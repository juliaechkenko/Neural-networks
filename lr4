import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier, MLPRegressor
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_absolute_error, mean_squared_error, r2_score

#номер варіанту
variant_number = 7

#кількість точок
n_samples = 100 + 2 * variant_number

#генерація випадкових даних
if variant_number % 2 == 1:  #непарний варіант - класифікація
    X, y = datasets.make_blobs(n_samples=n_samples, n_features=3, centers=3, random_state=42)
    # Візуалізація
    plt.figure(figsize=(8, 8))
    plt.subplot(121)
    plt.title("Blobs", fontsize="small")
    plt.scatter(X[:, 0], X[:, 1], marker="o", c=y, s=50, edgecolor="k")
else:  #парний варіант - регресія
    X, y = datasets.make_regression(n_samples=n_samples, n_features=5, n_targets=2, noise=0.1, random_state=42)

#розбиття на навчальні та тестові вибірки (80% навчання, 20% тест)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#для класифікації або регресії
if variant_number % 2 == 1:  # Класифікація
    model = MLPClassifier(hidden_layer_sizes=(100, 50), solver='adam', activation='relu', 
                          learning_rate_init=0.2, max_iter=450, random_state=42)
else:  
    model = MLPRegressor(hidden_layer_sizes=(100, 50), solver='adam', activation='relu', 
                         learning_rate_init=0.2, max_iter=450, random_state=42)

#навчання моделі
model.fit(X_train, y_train)

#оцінка якості моделей
if variant_number % 2 == 1:  #класифікація
    y_pred = model.predict(X_test)
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    
    #побудова графіка втрат
    plt.subplot(122)
    plt.title("Loss Curve")
    plt.plot(model.loss_curve_)
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()
else: 
    y_pred = model.predict(X_test)
    print("R2 Score:", r2_score(y_test, y_pred))
    print("Mean Absolute Error:", mean_absolute_error(y_test, y_pred))
    print("Mean Squared Error:", mean_squared_error(y_test, y_pred))

#зміна гіперпараметрів (метод навчання та функція активації)
if variant_number % 2 == 1:  # Класифікація
    model = MLPClassifier(hidden_layer_sizes=(100, 50), solver='sgd', activation='tanh', 
                          learning_rate_init=0.1, max_iter=450, random_state=42)
else:  
    model = MLPRegressor(hidden_layer_sizes=(100, 50), solver='sgd', activation='tanh', 
                         learning_rate_init=0.1, max_iter=450, random_state=42)

#навчання з новими гіперпараметрами
model.fit(X_train, y_train)

#оцінка з новими гіперпараметрами
if variant_number % 2 == 1:  # Класифікація
    y_pred = model.predict(X_test)
    print("Updated Accuracy:", accuracy_score(y_test, y_pred))
    print("Updated Classification Report:\n", classification_report(y_test, y_pred))
    print("Updated Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    
    #побудова графіка втрат
    plt.plot(model.loss_curve_)
    plt.title("Updated Loss Curve")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()
else: 
    y_pred = model.predict(X_test)
    print("Updated R2 Score:", r2_score(y_test, y_pred))
    print("Updated Mean Absolute Error:", mean_absolute_error(y_test, y_pred))
    print("Updated Mean Squared Error:", mean_squared_error(y_test, y_pred))

#завантаження та виведення набору даних про діабет
diabetes = datasets.load_diabetes()
print("Feature names:", diabetes.feature_names)
print("First 10 data points:\n", diabetes.data[:10])
print("First 10 target values:", diabetes.target[:10])

x_regr, y_regr = datasets.make_regression(n_samples=n_samples, n_features=5, n_targets=2, noise=1, random_state=42)

print("First 10 data points:\n", x_regr[:10])
print("First 10 target values:", y_regr[:10])

#генерація випадкових наборів даних для візуалізації
x_blobs, y_blobs = datasets.make_blobs(n_features=3, centers=4, cluster_std=2.0, random_state=42)
x_points, y_points = datasets.make_classification(n_features=3, n_redundant=0, n_informative=2, 
                                                   n_clusters_per_class=1, n_classes=4, random_state=42)

#візуалізація випадкових наборів даних
plt.figure(figsize=(8, 8))

plt.subplot(221)
plt.title("Blobs", fontsize="small")
plt.scatter(x_blobs[:, 0], x_blobs[:, 1], marker="o", c=y_blobs, s=50, edgecolor="k")

plt.subplot(222)
plt.title("Random Classification", fontsize="small")
plt.scatter(x_points[:, 0], x_points[:, 1], marker="o", c=y_points, s=50, edgecolor="k")

plt.tight_layout()
plt.show()

   

